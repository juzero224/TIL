# 4_ 머신러닝 모델의 검증 및 평가

- 아주 복잡한 패턴이 학습 가능

- 모든 패턴을 학습 시도

- 과대적합 (과적합)
  - 과적합을 이해하고 잘 컨트롤하는 것이 머신러닝의 성공 여부 결정
  - 모형이 복잡한 알고리즘은 정확도 좋지만, 일반오차가 큼
- 과대적합 문제 해결방법 : model 단순화, 훈련 데이터 확보



## 머신러닝 모델의 분석 절차

### 모델 기반 ==지도학습== 알고리즘의 일반적인 분석 절차

- 주어진 데이터 전처리 및 탐색탐색
- 적절한 모델을 선택
- 주어진 데이터로 모델을 **훈련**시킴
- 훈련된 모델을 적용하여 **새로운 데이터**에 대한 **예측**을 수행

![image-20221028040644900](C:/Users/yes47/AppData/Roaming/Typora/typora-user-images/image-20221028040644900.png)

- 일반화 능력 :up:
- 경계면을 찾고 나서 어느 쪽에 위치하는 지 파악 하고 예측



### 과대적합 (overfitting) 의 문제

- 주어진 자료는 거의 완벽한 예측이 가능하지만 미래의 새로운 자료에 대한 예측력이 떨어지는 문제
- 복잡한 알고리즘을 사용하여 데이터를 훈련하는 경우 과대적합 문제를 항상 염두에 두어야 함





### 모델의 검증 및 평가 개요

- 모델 평가의 필요성
  - 과대적합을 막고 **일반화 오차를 줄이기 위해서**는, 새로운 데이터에 얼마나 잘 일반화될지를 파악해야 함
  - 모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고, **평가만을 위한 데이터**를 확보할 필요가 있음





### 모델 검증 및 평가를 위한 데이터 구분 : Hold-out 방식

- 주어진 자료를 다음의 세 그룹으로 랜덤하게 분할한 뒤, 주어진 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용함

  1. 훈련 데이터 (Training data)

     - **모델의 학습**을 위해 사용되는 자료

     - F를 찾는 데 사용되는 train / 튜닝하는 데 사용되는 valid

  2. 검증 데이터 (Validation data)

     - 훈련 자료로 적합되는 모델을 최적의 성능으로 **튜닝하기 위해** 사용되는 자료
     - 훈련에 필요한 하이퍼파라미터 (hyperparameter)를 조정하거나, 변수선택 (model selecting) 등에 이용
     - 하이퍼파라미터 : 우리가 학습을 통해서 찾아내고자 모델의 모수가 아니라 그 model의 정확한 f 함숫값이 아니라 이 모델을 훈련하기 전에 사전에 주어지는 parameter. 학습을 하진 않지만 이 값으로 인해서 model의 성능이 달라질 수 있음

  3. 평가 데이터 (Test data)
     - 훈련 및 검증 자료로 적합된 최종 모형이 미래에 주어질 새로운 자료에 대하여 얼마나 좋은 성과를 갖는지를 평가하는데 사용되는 자료
     - Accuracy train >= Accuracy test



### 모델 검증 및 평가를 위한 데이터 구분 : K-fold 교차검증 (Cross-validation) 방식

- <u>자료의 수가 충분하지 않은 경우</u>에는 훈련 데이터에서 너무 많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차 검정 (cross-validation) 기법을 사용

  ![image-20221028041710142](C:/Users/yes47/AppData/Roaming/Typora/typora-user-images/image-20221028041710142.png)

1. 자료를 균등하게 k개의 그룹으로 분할한 뒤

2. 각 j에 대하여, j번쨰 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 모델을 적합

3. j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측오차를 구함

4. j=1,...,k에 대하여 위의 과정을 반복한 뒤, k개의 예측오차의 평균을 구함

5. 예측 오차의 평균값을 기준으로, 모델의 검증 또는 평가를 수행

   ![image-20221028041930833](C:/Users/yes47/AppData/Roaming/Typora/typora-user-images/image-20221028041930833.png)



- 계산량이 많아서 시간이 오래 걸린다는 단점이 있음
- 보유한 자료를 한번씩 다 사용할 수 있다는 장점이 있음





과대적합 : Test Error가 Training Error보다 너무 높은 경우

과소적합 : 모형이 단순해서 fitting이 안 좋은 경우



## 일반화 오차 및 편향-분산 트레이드 오프

### 편향-분산 트레이드 오프(Bias-Variance Trade off)

- 모델의 복잡한 정도에 따라 훈련 데이터와 평가 데이터의 예측오차는 일반적으로 다음과 같은 패턴을 보임

  ![image-20221028042219761](C:/Users/yes47/AppData/Roaming/Typora/typora-user-images/image-20221028042219761.png)



- 편향(Bias) = 정확도 개념
  - 복잡한 모델에서는 편향(Bias) 잘 낮음
  - model complexity가 낮으면 Bias가 높고, model complexity가 높으면 Bias가 낮음



- 분산(Variance) 
  - 자료가 바뀌면 model이 얼마나 크게 바뀌는가
  - model complexity가 높으면 variance도 커짐



- **일반화 오차 = 편향의 제곱과 분산의 합이 된다**



### 과대적합을 막기 위한 방법

- 훈련 데이터를 많이 확보
- 모델의 복잡도를 낮춤
  - 특성 변수의 수를 줄이거나 차원 축소
  - 파라미터에 규제(regularization)를 적용





## 문제

**Q1. 다음 중 과적합(overfitting) 문제를 막기위한 방법으로 올바른 것은?**

1. 평가(test) 자료 수를 늘린다.

2. **훈련(training) 자료 수를 늘린다.**

3. 목적함수에 규제(regularization)를 없앤다.

4. 모수(parameter)가 더 많이 포함된 모델을 선택한다.



- 머신러닝 모델에서의 과적합을 방지하기 위해서는 모델 파라미터에 규제를 적용하거나 특성변수를 줄여 **모수의 개수를 줄이는 등의 모델 복잡도를 낮추거나**, 모델이 잘 적합되도록 **훈련 데이터의 수를 늘이는 방법**이 있다. 평가데이터는 모델을 학습하는데 활용되지 않으므로, 평가데이터를 늘인다고 과적합을 줄일 수는 없다.



**Q2. 자료에 비하여 너무 복잡한 모델을 적용하는 경우에 발생할 수 있는 현상과 거리가 먼 것은?**

1. **편향(bias)이 증가한다.**

2. 분산(variance)이 증가한다. 

3. 과적합(overfitting)의 문제가 발생할 수 있다.

4. 훈련 자료는 잘 예측하지만 평가자료에 대한 예측력은 떨어지는 현상을 보일 수 있다.



- **모델 복잡도가 증가**하면, **편향은 줄어들지만, 분산이 늘어나 일반화 오차가 커지는 현상**을 보인다. 또 훈련 데이터는 잘 예측하지만, 평가 데이터의 예측력은 그에 미치지 못하는 과적합 현상을 보이게 된다.



**Q3. 모델을 최적의 성능으로 튜닝하기 위해 사용하는 데이터로, 모델에 필요한 하이퍼 파라미터를 조정하거나, 특성변수의 선택 등의 목적으로 활용되는 자료를 무엇이라고 하는가?**

1. 훈련(training) 데이터 

2. 평가(test) 데이터

3. **검증(validation) 데이터**

4. 학습(learning) 데이터



- 검증 데이터는 훈련 데이터의 일부로, 하이퍼파라미터 및 변수 선택 등의 모델 튜닝을 위해 활용된다.