{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed4a5cc",
   "metadata": {},
   "source": [
    "## 문제 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e4cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 11 유형(DataSet_11.csv 이용)\n",
    "\n",
    "# 구분자 : comma(“,”), 470 Rows, 4 Columns, UTF-8 인코딩\n",
    "\n",
    "# 세계 각국의 행복지수를 비롯한 여러 정보를 조사한 DS리서치는\n",
    "# 취합된 자료의 현황 파악 및 간단한 통계분석을 실시하고자 한다.\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# Country / 국가명 / String\n",
    "# Happiness_Rank / 당해 행복점수 순위 / Double\n",
    "# Happiness_Score / 행복점수 / Double\n",
    "# year / 년도 / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data11 = pd.read_csv('./DataSet/DataSet_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f64cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.분석을 위해 3년 연속 행복지수가 기록된 국가의 데이터를 사용하고자 한다. \n",
    "# 3년 연속 데이터가 기록되지 않은 국가의 개수는?\n",
    "# - 국가명 표기가 한 글자라도 다른 경우 다른 국가로 처리하시오.\n",
    "# - 3년 연속 데이터가 기록되지 않은 국가 데이터는 제외하고 이를 향후 분석에서\n",
    "# 활용하시오.(답안 예시) 1\n",
    "# =============================================================================\n",
    "\n",
    "# 1. 국가명 표기가 한 글자라도 다른 경우 다른 국가로 처리\n",
    "q11_1 = data11.groupby('Country').apply(len)\n",
    "\n",
    "# 3년 연속 데이터가 기록되지 않은 국가 데이터\n",
    "len(q11_1[q11_1 < 3])\n",
    "\n",
    "# 답 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c0564f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Latvia', 'Romania', 'Togo'], dtype='object', name='Country')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.(1번 산출물을 활용하여) 2017년 행복지수와 2015년 행복지수를 활용하여 국가별\n",
    "# 행복지수 증감률을 산출하고 행복지수 증감률이 가장 높은 3개 국가를 행복지수가\n",
    "# 높은 순서대로 차례대로 기술하시오.\n",
    "# 증감률 = (2017년행복지수−2015년행복지수)/2\n",
    "# \n",
    "# (답안 예시) Korea, Japan, China\n",
    "# =============================================================================\n",
    "\n",
    "# 1번 산출물\n",
    "country_list = q11_1[q11_1 == 3].index\n",
    "\n",
    "q11_2 = data11[data11.Country.isin(country_list)]\n",
    "\n",
    "# 2. 2017년 행복지수와 2015년 행복지수를 활용\n",
    "q11_2_tab = pd.pivot_table(q11_2, index = 'Country',\n",
    "                            columns = 'year',\n",
    "                            values = 'Happiness_Score')\n",
    "\n",
    "# 3. 국가별 행복지수 증감률을 산출\n",
    "q11_2_tab['ratio'] = (q11_2_tab[2017] - q11_2_tab[2015]) / 2\n",
    "\n",
    "# 4. 복지수 증감률이 가장 높은 3개 국가를 행복지수가 높은 순서대로\n",
    "q11_2_tab.ratio.nlargest(3).index\n",
    "\n",
    "# 답 : 'Latvia', 'Romania', 'Togo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "892d9765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004276725037677239"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.(1번 산출물을 활용하여) 년도별 행복지수 평균이 유의미하게 차이가 나는지\n",
    "# 알아보고자 한다. \n",
    "# 이와 관련하여 적절한 검정을 사용하고 검정통계량을 기술하시오.\n",
    "# - 해당 검정의 검정통계량은 자유도가 2인 F 분포를 따른다.\n",
    "# - 검정통계량은 소수점 넷째 자리까지 기술한다. (답안 예시) 0.1234\n",
    "# =============================================================================\n",
    "\n",
    "# (참고)\n",
    "# from statsmodels.formula.api import ols\n",
    "# from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# 1. 1번 산춣물 활용\n",
    "country_list = q11_1[q11_1 == 3].index\n",
    "q11_3 = data11[data11.Country.isin(country_list)]\n",
    "\n",
    "# 2. 년도별 행복지수 평균\n",
    "q11_3_tab = pd.pivot_table(q11_3,\n",
    "                          index = 'Country',\n",
    "                          columns = 'year',\n",
    "                          values = 'Happiness_Score')\n",
    "\n",
    "q11_3_f = f_oneway(q11_3_tab[2015],q11_3_tab[2016],q11_3_tab[2017])\n",
    "# F_onewayResult(statistic=0.004276725037689305, pvalue=0.9957324489944479)\n",
    "\n",
    "# 3. anova (ols 적용)\n",
    "q11_3_out = ols('Happiness_Score~C(year)', q11_3).fit()\n",
    "\n",
    "q11_3_out.summary()\n",
    "anova_lm(q11_3_out)\n",
    "\n",
    "# 4. 검정통계량\n",
    "q11_3_f.statistic  # 0.004276725037689305\n",
    "anova_lm(q11_3_out)['F'][0]  # 0.004276725037677239\n",
    "\n",
    "# 답 : 0.0042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32a4e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "  2015   2016  -0.0112 0.9962 -0.3261 0.3038  False\n",
      "  2015   2017   -0.001    1.0 -0.3159  0.314  False\n",
      "  2016   2017   0.0102 0.9968 -0.3047 0.3251  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# [참고]\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd  # 다중비교, 사후 검정\n",
    "tukey_out=pairwise_tukeyhsd(q11_3['Happiness_Score'], q11_3['year'])\n",
    "\n",
    "print(tukey_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02968bb2",
   "metadata": {},
   "source": [
    "## 문제 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98f85ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 12 유형(DataSet_12.csv 이용)\n",
    "\n",
    "# 구분자 : comma(“,”), 5000 Rows, 7 Columns, UTF-8 인코딩\n",
    "\n",
    "# 직장인의 독서 실태를 분석하기 위해서 수도권 거주자 5000명을\n",
    "# 대상으로 간단한 인적 사항과 연간 독서량 정보를 취합하였다.\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# Age / 나이 / String\n",
    "# Gender / 성별(M: 남성) / String\n",
    "# Dependent_Count / 부양가족 수 / Double\n",
    "# Education_Level / 교육 수준 / String\n",
    "# is_Married / 결혼 여부(1: 결혼) / Double\n",
    "# Read_Book_per_Year / 연간 독서량(권) / Double\n",
    "# Income_Range / 소득 수준에 따른 구간(A < B < C < D < E)이며 X는\n",
    "# 정보 누락 / String\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data12 = pd.read_csv('./DataSet/DataSet_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d51483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968432255640413"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.수치형 변수를 대상으로 피어슨 상관분석을 실시하고 연간 독서량과 가장\n",
    "# 상관관계가 강한 변수의 상관계수를 기술하시오\n",
    "# - 상관계수는 반올림하여 소수점 셋째 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "\n",
    "# 1.수치형 변수를 대상\n",
    "x_list = list(data12.columns[data12.dtypes == 'int64'])\n",
    "# ['Dependent_Count', 'is_Married', 'Read_Book_per_Year']\n",
    "\n",
    "# 2. 피어슨 상관분석\n",
    "q12_1 = data12[x_list].corr().drop('Read_Book_per_Year')['Read_Book_per_Year']\n",
    "\n",
    "abs(q12_1).max()\n",
    "# 0.1325908414916882 \n",
    "\n",
    "# 답 : 0.797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "410123db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2685589229897138"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.석사 이상(석사 및 박사) 여부에 따라서 연간 독서량 평균이 유의미하게 다른지 가설\n",
    "# 검정을 활용하여 알아보고자 한다. 독립 2표본 t검정을 실시했을 때 \n",
    "# 유의 확률(p\u0002value)의 값을 기술하시오.\n",
    "# - 등분산 가정 하에서 검정을 실시한다.\n",
    "# - 유의 확률은 반올림하여 소수점 셋째 자리까지 기술한다. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "\n",
    "q12_2 = data12.copy()\n",
    "\n",
    "# 1. 석사 이상(석사 및 박사) 여부\n",
    "q12_2['grad'] = data12.Education_Level.isin(['석사','박사'])+0\n",
    "\n",
    "# 2. 독립 2표본 t검정 (ttest_ind) 등분산 가정\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "q12_2_1 = q12_2[q12_2.grad == 1]['Read_Book_per_Year']\n",
    "q12_2_0 = q12_2[q12_2.grad == 0]['Read_Book_per_Year']\n",
    "\n",
    "q12_2_out = ttest_ind(q12_2_1, q12_2_0, equal_var=True)\n",
    "\n",
    "q12_2_out.pvalue\n",
    "\n",
    "# 답 : 0.269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a54066f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.964402066284841"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.독서량과 다른 수치형 변수의 관계를 다중선형회귀분석을 활용하여 알아보고자 한다. \n",
    "# 연간 독서량을 종속변수, 나머지 수치형 자료를 독립변수로 한다. 이렇게 생성한\n",
    "# 선형회귀 모델을 기준으로 다른 독립변수가 고정이면서 나이만 다를 때, 40살은 30살\n",
    "# 보다 독서량이 얼마나 많은가?\n",
    "# - 학사 이상이면서 소득 구간 정보가 있는 데이터만 사용하여 분석을 실시하시오.\n",
    "# - 결과값은 반올림하여 정수로 표기하시오. (답안 예시) 1\n",
    "# =============================================================================\n",
    "\n",
    "# (참고)\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# 1. 학사 이상이면서 소득 구간 정보가 있는 데이터만 사용\n",
    "q12_3 = data12[data12['Education_Level'].isin(['학사','석사','박사'])]\n",
    "q12_3 = q12_3[~q12_3.Income_Range.isin(['X'])]\n",
    "\n",
    "# 2. 연간 독서량을 종속변수, 나머지 수치형 자료를 독립변수\n",
    "var_list = list(q12_3.columns[q12_3.dtypes == 'int64'].drop('Read_Book_per_Year'))\n",
    "\n",
    "# 선형회귀 모델\n",
    "q12_3_out = ols('Read_Book_per_Year~' + '+'.join(var_list), q12_3).fit()\n",
    "\n",
    "q12_3_out.summary()\n",
    "\n",
    "q12_3_out.params\n",
    "# Intercept         -0.382146\n",
    "# Age                0.796440\n",
    "# Dependent_Count   -0.250269\n",
    "# is_Married         0.049624\n",
    "\n",
    "q12_3_out.params['Age']*(40-30)\n",
    "\n",
    "# 답 : 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f2a2d",
   "metadata": {},
   "source": [
    "## 문제 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c675b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 13 유형(DataSet13_train.csv / DataSet13_test.csv  이용)\n",
    "\n",
    "# 구분자 : \n",
    "#     comma(“,”), 1500 Rows, 10 Columns, UTF-8 인코딩 / \n",
    "#     comma(“,”), 500 Rows, 10 Columns, UTF-8 인코딩\n",
    "\n",
    "# 전국의 데이터 분석가 2000명을 대상으로 이직 관련 설문조사를 실시하였다. \n",
    "# 설문 대상자의 특성 및 이직 의사와 관련 인자를 면밀히 살펴보기 위해 다양한\n",
    "# 분석을 실시하고자 한다.\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# city_development_index / 거주 도시 개발 지수 / Double\n",
    "# gender / 성별 / String\n",
    "# relevent_experience / 관련 직무 경험 여부(1 : 유경험) / Integer\n",
    "# enrolled_university / 대학 등록 형태(1 : 풀타임/파트타임) / Integer\n",
    "# education_level / 교육 수준 / String\n",
    "# major_discipline / 전공 / String\n",
    "# experience / 경력 / Double\n",
    "# last_new_job / 현 직장 직전 직무 공백 기간 / Double\n",
    "# training_hours / 관련 직무 교육 이수 시간 / Double\n",
    "# target / 이직 의사 여부(1 : 의사 있음) / Integer\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data13 = pd.read_csv('./DataSet/DataSet_13_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d546f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>last_new_job</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Female</th>\n",
       "      <th>experience</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_new_job</th>\n",
       "      <td>0.451898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Male</th>\n",
       "      <th>experience</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_new_job</th>\n",
       "      <td>0.411155</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     experience  last_new_job\n",
       "gender                                       \n",
       "Female experience      1.000000      0.451898\n",
       "       last_new_job    0.451898      1.000000\n",
       "Male   experience      1.000000      0.411155\n",
       "       last_new_job    0.411155      1.000000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.(Dataset_13_train.csv를 활용하여) 경력과 최근 이직시 공백기간의 상관관계를 보고자\n",
    "# 한다. 남여별 피어슨 상관계수를 각각 산출하고 더 높은 상관계수를 기술하시오.\n",
    "# - 상관계수는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# =============================================================================\n",
    "data13.columns\n",
    "# ['city_development_index', 'gender', 'relevent_experience',\n",
    "#        'enrolled_university', 'education_level', 'major_discipline',\n",
    "#        'experience', 'last_new_job', 'training_hours', 'target']\n",
    "\n",
    "# 1. 경력과 최근 이직시 공백기간의 상관관계\n",
    "data13.groupby('gender')[['experience','last_new_job']].corr()\n",
    "\n",
    "# Female 0.451898 > 0.411155\n",
    "# 답 : 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "270707e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.(Dataset_13_train.csv를 활용하여) 기존 데이터 분석 관련 직무 경험과 이직 의사가 서로\n",
    "# 관련이 있는지 알아보고자 한다. 이를 위해 독립성 검정을 실시하고 해당 검정의 p-value를 기술하시오.\n",
    "# - 검정은 STEM 전공자를 대상으로 한다.\n",
    "# - 검정은 충분히 발달된 도시(도시 개발 지수가 제 85 백분위수 초과)에 거주하는 사람을\n",
    "# 대상으로 한다.\n",
    "# - 이직 의사 여부(target)은 문자열로 변경 후 사용한다.\n",
    "# - p-value는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# =============================================================================\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 1. 이직 의사 여부(target)은 문자열로 변경 \n",
    "q13_2 = data13.copy()\n",
    "q13_2.target = q13_2.target.astype('str')\n",
    "# q13_2.info()\n",
    "\n",
    "# 2.  STEM 전공자, 충분히 발달된 도시(도시 개발 지수가 제 85 백분위수 초과)에 거주하는 사람을 대상\n",
    "q13_2['city_development_index'].value_counts()\n",
    "base = q13_2['city_development_index'].quantile(0.85)\n",
    "\n",
    "q13_2_df = q13_2[(q13_2.major_discipline == 'STEM') & (q13_2['city_development_index'] > base)]\n",
    "\n",
    "# 3. 범주형 데이터 독립성 검정을 실시 : 카이스퀘어 검정\n",
    "q13_2_tab = pd.crosstab(index=q13_2_df.relevent_experience, columns=q13_2_df.target)\n",
    "\n",
    "chi_test = chi2_contingency(q13_2_tab)\n",
    "\n",
    "pvalue = chi_test[1]\n",
    "\n",
    "round(pvalue, 2)\n",
    "# 답 : 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "525f02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 0.67\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.(Dataset_13_train.csv를 활용하여) 인사팀에서는 어떤 직원이 이직 의사를 가지고 있을지\n",
    "# 사전에 파악하고 1:1 면담 등 집중 케어를 하고자 한다. 이를 위해 의사결정 나무를\n",
    "# 활용하여 모델을 생성하고 그 정확도를 확인하시오.\n",
    "# - target을 종속변수로 하고 나머지 변수 중 String이 아닌 변수를 독립변수로 한다.\n",
    "# - 학습은 전부 기본값으로 실시한다.\n",
    "# - 평가는 \"Dataset_13_test.csv\" 데이터로 실시한다.\n",
    "# - 정확도는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# \n",
    "# =============================================================================\n",
    "\n",
    "# (참고)\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# random_state = 123\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "test = pd.read_csv('./DataSet/DataSet_13_test.csv')\n",
    "\n",
    "# data13.info()\n",
    "\n",
    "# 1. target을 종속변수로 하고 나머지 변수 중 String이 아닌 변수를 독립변수로 한다.\n",
    "var_list = data13.columns[data13.dtypes != 'object'].drop('target')\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "dt.fit(data13[var_list], data13['target'])\n",
    "\n",
    "score = dt.score(test[var_list], test['target'])\n",
    "\n",
    "print(f'답 : {round(score,2)}')\n",
    "# 답 : 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4ba6b526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'published', 'subject', 'level', 'price', 'subscribers',\n",
       "       'reviews', 'lectures', 'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 14 유형(DataSet_14.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 2000 Rows, 9 Columns, UTF-8 인코딩\n",
    "#\n",
    "# 온라인 교육업체 싱글캠퍼스에서 런칭한 교육 플랫폼을 보다\n",
    "# 체계적으로 운영하기 위해 2014년부터 2016년 동안 개설된 강좌\n",
    "# 2000개를 대상으로 강좌 실적 및 고객의 서비스 분석을 실시하려고\n",
    "# 한다. 관련 데이터는 다음과 같다.\n",
    "#\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# id / 강좌 일련번호 / Double\n",
    "# published / 강과 개설일 / String\n",
    "# subject / 강좌 대주제 / String\n",
    "# level / 난이도 / String\n",
    "# price / 가격(만원) / Double\n",
    "# subscribers / 구독자 수(결제 인원) / Double\n",
    "# reviews / 리뷰 개수 / Double\n",
    "# lectures / 강좌 영상 수 / Double\n",
    "# duration / 강좌 총 길이(시간) / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data14 = pd.read_csv('./DataSet/DataSet_14.csv')\n",
    "data14.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d8a729fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 59\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.결제 금액이 1억 이상이면서 구독자의 리뷰 작성 비율이 10% 이상인 교육의 수는?\n",
    "# - 결제 금액은 강좌 가격에 구독자 수를 곱한 값이다.\n",
    "# - 리뷰 작성 비율은 리뷰 개수에 구독자 수를 나눈 값이다. (답안 예시) 1\n",
    "# =============================================================================\n",
    "\n",
    "q14_1 = data14.copy()\n",
    "\n",
    "# 1. 결제 금액은 강좌 가격에 구독자 수를 곱한 값\n",
    "q14_1['income'] = q14_1['price'] * q14_1['subscribers']\n",
    "\n",
    "# 2. 리뷰 작성 비율은 리뷰 개수에 구독자 수를 나눈 값\n",
    "q14_1['ratio'] = q14_1['reviews'] / q14_1['subscribers']\n",
    "\n",
    "# 3. 결제 금액이 1억 이상이면서 구독자의 리뷰 작성 비율이 10% 이상인 교육의 수\n",
    "result = len(q14_1[(q14_1.income >= 10000) & (q14_1.ratio >= 0.1)])\n",
    "\n",
    "print(f'답 : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23481e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribers</th>\n",
       "      <td>0.034392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                price  subscribers\n",
       "price        1.000000     0.034392\n",
       "subscribers  0.034392     1.000000"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.강좌 가격이 비쌀수록 구독자 숫자는 줄어든다는 가설을 확인하기 위해 상관분석을\n",
    "# 실시하고자 한다. 2016년 개설된 Web Development 강좌를 대상으로 강좌 가격과\n",
    "# 구독자 수의 피어슨 상관관계를 기술하시오.\n",
    "# - 상관계수는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# =============================================================================\n",
    "\n",
    "q14_2 = data14.copy()\n",
    "\n",
    "# 1. 2016년 개설된 Web Development 강좌를 대상\n",
    "q14_2.published = pd.to_datetime(q14_2.published)\n",
    "q14_2['year'] = q14_2.published.dt.year\n",
    "\n",
    "q14_2_df = q14_2[(q14_2.year == 2016) & (q14_2.subject == 'Web Development')]\n",
    "\n",
    "# 2. 강좌 가격과 구독자 수의 피어슨 상관관계\n",
    "q14_2_df[['price','subscribers']].corr()\n",
    "\n",
    "# 0.034392\n",
    "# 답 : 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7112687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 18.5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.유저가 서비스 사용에 익숙해지고 컨텐츠의 좋은 내용을 서로 공유하려는 경향이\n",
    "# 전반적으로 증가하는 추세라고 한다. 이를 위해 먼저 강좌 개설 년도별 구독자의 리뷰\n",
    "# 작성 비율의 평균이 강좌 개설 년도별로 차이가 있는지 일원 분산 분석을 통해서\n",
    "# 알아보고자 한다. 이 때 검정통계량을 기술하시오.\n",
    "# - 검정통계량은 반올림하여 소수점 첫째 자리까지 기술하시오. (답안 예시) 0.1\n",
    "#\n",
    "# (참고)\n",
    "# from statsmodels.formula.api import ols\n",
    "# from statsmodels.stats.anova import anova_lm\n",
    "# =============================================================================\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "q14_3 = data14.copy()\n",
    "q14_3.published = pd.to_datetime(q14_3.published)\n",
    "q14_3['year'] = q14_3.published.dt.year\n",
    "q14_3['ratio'] = q14_3['reviews'] / q14_3['subscribers']\n",
    "\n",
    "# 1. 강좌 개설 년도별 구독자의 리뷰 작성 비율의 평균\n",
    "model = ols('ratio ~ C(year)', q14_3).fit()\n",
    "result = anova_lm(model)\n",
    "\n",
    "print(f'답 : {round(result.F[0], 1)}')\n",
    "# 답 : 18.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb2ccf",
   "metadata": {},
   "source": [
    "## 문제 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "33b1d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 05 유형(Dataset_05_Mart_POS.csv /  이용)\n",
    "#\n",
    "# =============================================================================\n",
    "# Dataset_05_Mart_POS.csv \n",
    "# 구분자 : comma(“,”), 20488 Rows, 3 Columns, UTF-8 인코딩\n",
    "# =============================================================================\n",
    "#\n",
    "# 원룸촌에 위치한 A마트는 데이터 분석을 통해 보다 체계적인 재고관리와\n",
    "# 운영을 하고자 한다. 이를 위해 다음의 두 데이터 세트를 준비하였다.\n",
    "#\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# Member_number / 고객 고유 번호 / Double\n",
    "# Date / 구매일 / String\n",
    "# itemDescription / 상품명 / String\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset_05_item_list.csv \n",
    "# 구분자 : comma(“,”), 167 Rows, 4 Columns, UTF-8 인코\n",
    "# =============================================================================\n",
    "#\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# prod_id / 상품 고유 번호 / Double\n",
    "# prod_nm / 상품명 / String\n",
    "# alcohol / 주류 상품 여부(1 : 주류) / Integer\n",
    "# frozen / 냉동 상품 여부(1 : 냉동) / Integer\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "data15_mart = pd.read_csv('./DataSet/DataSet_15_Mart_POS.csv')\n",
    "data15_item = pd.read_csv('./DataSet/Dataset_15_item_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "840aa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 7\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.(Dataset_05_Mart_POS.csv를 활용하여) 가장 많은 제품이 팔린 날짜에 가장 많이 팔린\n",
    "# 제품의 판매 개수는? (답안 예시) 1\n",
    "# =============================================================================\n",
    "\n",
    "date = data15_mart.Date.value_counts().idxmax()\n",
    "result = data15_mart[data15_mart.Date == date].itemDescription.value_counts().max()\n",
    "\n",
    "print(f'답 : {result}')\n",
    "# 답 : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c875132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 0.02\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. (Dataset_05_Mart_POS.csv, Dataset_05_item_list.csv를 활용하여) 고객이 주류 제품을\n",
    "# 구매하는 요일이 다른 요일에 비해 금요일과 토요일이 많을 것이라는 가설을 세웠다. \n",
    "# 이를 확인하기 위해 금요일과 토요일의 일별 주류제품 구매 제품 수 평균과 다른\n",
    "# 요일의 일별 주류제품 구매 제품 수 평균이 서로 다른지 비교하기 위해 독립 2표본\n",
    "# t검정을 실시하시오. \n",
    "# 해당 검정의 p-value를 기술하시오.\n",
    "# - 1분기(1월 ~ 3월) 데이터만 사용하여 분석을 실시하시오.\n",
    "# - 등분산 가정을 만족하지 않는다는 조건 하에 분석을 실시하시오.\n",
    "# - p-value는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# =============================================================================\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "mart = data15_mart.copy()\n",
    "item = data15_item.copy()\n",
    "\n",
    "# 1. 구매하는 요일이 다른 요일에 비해 금요일과 토요일이 많을 것\n",
    "mart['Date'] = pd.to_datetime(mart.Date)\n",
    "mart['year'] = mart['Date'].dt.year\n",
    "mart['month'] = mart['Date'].dt.month\n",
    "mart['day'] = mart['Date'].dt.day_name(locale='ko_kr')\n",
    "mart['date'] = np.where(mart['day'].isin(['금요일','토요일']), 1, 0)\n",
    "\n",
    "# 2. 테이블 결합\n",
    "q15_2 = pd.merge(mart, item, how='left', left_on='itemDescription', right_on='prod_nm')\n",
    "\n",
    "# 3. 필터링 1분기(1월 ~ 3월) 데이터\n",
    "q15_2_df = q15_2[q15_2['month'].isin([1,2,3])]\n",
    "\n",
    "# 4. 금요일과 토요일의 일별 주류제품 구매 제품 수 평균과 다른\n",
    "# 요일의 일별 주류제품 구매 제품 수 평균이 서로 다른지 비교하기 위해 독립 2표본 t검정\n",
    "\n",
    "# -  일별 주류제품 구매 제품 수 \n",
    "q15_2_df2 = pd.pivot_table(q15_2_df, index='Date',\n",
    "                          columns='date', \n",
    "                          values='alcohol',\n",
    "                          aggfunc='sum')\n",
    "\n",
    "# 5. ttest 진행 (등분산 X)\n",
    "q15_2_out = ttest_ind(q15_2_df2[1].dropna(),\n",
    "                     q15_2_df2[0].dropna(),\n",
    "                     equal_var=False)\n",
    "\n",
    "# 6. pvalue\n",
    "q15_2_out.pvalue\n",
    "# Ttest_indResult(statistic=-2.335264239960428, pvalue=0.023062611047582393)\n",
    "\n",
    "print(f'답 : {round(q15_2_out.pvalue,2)}')\n",
    "# 답 : 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e8e99540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답 : 0.52\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.(Dataset_05_Mart_POS.csv를 활용하여) 1년 동안 가장 많이 판매된 10개 상품을 주력\n",
    "# 상품으로 설정하고 특정 요일에 프로모션을 진행할지 말지 결정하고자 한다. 먼저\n",
    "# 요일을 선정하기 전에 일원 분산 분석을 통하여 요일별 주력 상품의 판매 개수의\n",
    "# 평균이 유의미하게 차이가 나는지 알아보고자 한다. 이와 관련하여 일원 분산 분석을\n",
    "# 실시하고 p-value를 기술하시오.\n",
    "# - p-value는 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 0.12\n",
    "# \n",
    "# (참고)\n",
    "# from statsmodels.formula.api import ols\n",
    "# from statsmodels.stats.anova import anova_lm\n",
    "# =============================================================================\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "mart = data15_mart.copy()\n",
    "\n",
    "# 1. 1년 동안 가장 많이 판매된 10개 상품을 주력 상품으로 설정\n",
    "item = list(mart['itemDescription'].value_counts().nlargest(10).index)\n",
    "\n",
    "# 2. 일원 분산 분석을 통하여 요일별 주력 상품의 판매 개수의 평균\n",
    "# - 요일별 주력 상품의 판매 개수\n",
    "mart['Date'] = pd.to_datetime(mart.Date)\n",
    "mart['year'] = mart['Date'].dt.year\n",
    "mart['month'] = mart['Date'].dt.month\n",
    "mart['day'] = mart['Date'].dt.day_name(locale='ko_kr')  # 요일\n",
    "\n",
    "q15_3 = mart[mart['itemDescription'].isin(item)]\n",
    "\n",
    "q15_3_df = q15_3.groupby(['Date','day'])['itemDescription'].apply(len).reset_index()\n",
    "\n",
    "# pd.pivot_table(q15_3, index=['Date','day'],\n",
    "#               values='itemDescription',\n",
    "#               aggfunc='count').reset_index()\n",
    "\n",
    "# 3.  평균이 유의미하게 차이가 나는지 일원분산분석\n",
    "q15_3_ols = ols('itemDescription ~ day', q15_3_df).fit()\n",
    "result = anova_lm(q15_3_ols)\n",
    "\n",
    "print(f\"답 : {round(result['PR(>F)'][0], 2)}\")\n",
    "\n",
    "# 답 : 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667e29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
